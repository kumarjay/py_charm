{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date    Open    High     Low   Close      Volume\n",
       "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train=pd.read_csv(r'G:\\dAtAsS\\Google_Stock_Price_Train.txt')\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=dataset_train.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325.25],\n",
       "       [331.27],\n",
       "       [329.83],\n",
       "       ...,\n",
       "       [793.7 ],\n",
       "       [783.33],\n",
       "       [782.75]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08581368],\n",
       "       [0.09701243],\n",
       "       [0.09433366],\n",
       "       ...,\n",
       "       [0.95725128],\n",
       "       [0.93796041],\n",
       "       [0.93688146]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max=MinMaxScaler(feature_range=(0,1))\n",
    "min_max_scaled=min_max.fit_transform(training_set)\n",
    "min_max_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "\n",
    "for i in range(60,1258):\n",
    "    x_train.append(min_max_scaled[i-60:i,0])\n",
    "    y_train.append(min_max_scaled[i,0])\n",
    "    \n",
    "x_train, y_train=np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train=np.reshape(x_train, (x_train.shape[0], x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60, 1258):\n",
    "    X_train.append(min_max_scaled[i-60:i, 0])\n",
    "    y_train.append(min_max_scaled[i, 0])\n",
    "X_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Reshaping\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "seq.add(Dropout(0.2))\n",
    "\n",
    "seq.add(LSTM(units=50, return_sequences=True))\n",
    "seq.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "seq.add(LSTM(units=50, return_sequences=True))\n",
    "seq.add(Dropout(0.2))\n",
    "\n",
    "seq.add(LSTM(units=50))\n",
    "seq.add(Dropout(0.2))\n",
    "\n",
    "seq.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1198/1198 [==============================] - 9s 8ms/step - loss: 0.0547\n",
      "Epoch 2/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0062\n",
      "Epoch 3/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0050\n",
      "Epoch 4/100\n",
      " 288/1198 [======>.......................] - ETA: 3s - loss: 0.0069"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-11bb843450e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "seq.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "seq.fit(x_train, y_train, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_24_input to have 3 dimensions, but got array with shape (1198, 60)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-480f250a586d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# Fitting the RNN to the Training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_24_input to have 3 dimensions, but got array with shape (1198, 60)"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(x_train, y_train, epochs = 100, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "1198/1198 [==============================] - 12s 10ms/step - loss: 0.0431\n",
      "Epoch 2/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0062\n",
      "Epoch 3/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0054\n",
      "Epoch 4/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0051\n",
      "Epoch 5/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0052\n",
      "Epoch 6/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0047\n",
      "Epoch 7/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0040\n",
      "Epoch 8/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0046\n",
      "Epoch 9/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0043\n",
      "Epoch 10/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0045\n",
      "Epoch 11/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0038\n",
      "Epoch 12/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0038\n",
      "Epoch 13/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0041\n",
      "Epoch 14/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0038\n",
      "Epoch 15/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0041\n",
      "Epoch 16/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0036\n",
      "Epoch 17/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0042\n",
      "Epoch 18/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0035\n",
      "Epoch 19/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0033\n",
      "Epoch 20/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0037\n",
      "Epoch 21/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0033\n",
      "Epoch 22/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0031\n",
      "Epoch 23/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0031\n",
      "Epoch 24/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0035\n",
      "Epoch 25/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0033\n",
      "Epoch 26/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0034\n",
      "Epoch 27/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0028\n",
      "Epoch 28/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0030\n",
      "Epoch 29/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0028\n",
      "Epoch 30/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0031\n",
      "Epoch 31/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0031\n",
      "Epoch 32/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0031\n",
      "Epoch 33/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0027\n",
      "Epoch 34/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0029\n",
      "Epoch 35/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0027\n",
      "Epoch 36/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0030\n",
      "Epoch 37/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0025\n",
      "Epoch 38/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0030\n",
      "Epoch 39/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0028\n",
      "Epoch 40/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0025\n",
      "Epoch 41/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0023\n",
      "Epoch 42/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0026\n",
      "Epoch 43/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0027\n",
      "Epoch 44/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0025\n",
      "Epoch 45/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0025\n",
      "Epoch 46/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0025\n",
      "Epoch 47/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0022\n",
      "Epoch 48/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0022\n",
      "Epoch 49/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0023\n",
      "Epoch 50/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0024\n",
      "Epoch 51/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0022\n",
      "Epoch 52/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0026\n",
      "Epoch 53/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0024\n",
      "Epoch 54/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0023\n",
      "Epoch 55/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0023\n",
      "Epoch 56/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0022\n",
      "Epoch 57/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0020\n",
      "Epoch 58/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0021\n",
      "Epoch 59/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0023\n",
      "Epoch 60/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0022\n",
      "Epoch 61/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0020\n",
      "Epoch 62/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0020\n",
      "Epoch 63/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0022\n",
      "Epoch 64/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0019\n",
      "Epoch 65/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0018\n",
      "Epoch 66/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0017\n",
      "Epoch 67/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0019\n",
      "Epoch 68/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0020\n",
      "Epoch 69/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0018\n",
      "Epoch 70/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0018\n",
      "Epoch 71/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0018\n",
      "Epoch 72/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0017\n",
      "Epoch 73/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0016\n",
      "Epoch 74/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0017\n",
      "Epoch 75/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0018\n",
      "Epoch 76/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0016\n",
      "Epoch 77/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0017\n",
      "Epoch 78/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0017\n",
      "Epoch 79/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 80/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0017\n",
      "Epoch 81/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 82/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0015\n",
      "Epoch 83/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0017\n",
      "Epoch 84/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 85/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0015\n",
      "Epoch 86/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 87/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 88/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0015\n",
      "Epoch 89/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 90/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0014\n",
      "Epoch 91/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0015\n",
      "Epoch 92/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0016\n",
      "Epoch 93/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0015\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0017\n",
      "Epoch 95/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0016\n",
      "Epoch 96/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0015\n",
      "Epoch 97/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0017\n",
      "Epoch 98/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0015\n",
      "Epoch 99/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0015\n",
      "Epoch 100/100\n",
      "1198/1198 [==============================] - 5s 4ms/step - loss: 0.0015\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'G:\\\\dAtAsS\\\\Google_Stock_Price_Test.csv' does not exist: b'G:\\\\dAtAsS\\\\Google_Stock_Price_Test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-241b4cdcf731>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;31m# Getting the real stock price of 2017\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m \u001b[0mdataset_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'G:\\dAtAsS\\Google_Stock_Price_Test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[0mreal_stock_price\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'G:\\\\dAtAsS\\\\Google_Stock_Price_Test.csv' does not exist: b'G:\\\\dAtAsS\\\\Google_Stock_Price_Test.csv'"
     ]
    }
   ],
   "source": [
    "training_set = dataset_train.iloc[:, 1:2].values\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 1258):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "\n",
    "\n",
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)\n",
    "\n",
    "\n",
    "\n",
    "# Part 3 - Making the predictions and visualising the results\n",
    "\n",
    "# Getting the real stock price of 2017\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXmcTfX7wN+PfSuErwoh+9YMhqyDrJVoIa1fbUhJ9S3t+689pZJIaRGVLIlSSYhIkaUk+x5pbGPsZub5/fGc4eLOzJ0xd86d8Xm/Xud17znnc87nOXc5z/k820dUFYfD4XA4TiSP3wI4HA6HIzJxCsLhcDgcQXEKwuFwOBxBcQrC4XA4HEFxCsLhcDgcQXEKwuFwOBxBcQrC4Rsi8pSIjPJbjrQQkfUi0i5M5/5TRFqH49zhQkRURKp674eJyOOZPM9eETk/a6VzZDVOQTgQkWtE5BcR2Sci/3rv7xAR8Vu21BCRFiIyV0TiRWSniMwRkUbevptE5CcfZFLvM9wrIn+LyGsikje19qpaR1VnZrEMM0XkoCfDdhGZICLnZGUfKajq7ar6fyHKdNsJxxZT1bXhkMuRdTgFcZojIvcBbwCvAGcDZYHbgeZAAR9FSxURORP4ChgMnAWUA54GDvkpl0eUqhYD2gLXAb1ObCAi+cIsQz9PhupACWBQsEZpKS+HA5yCOK0RkeLAM8AdqjpOVRPUWKSq16vqoZR2IjJSROJEZIOIPCYiebx9ebz1Dd7oY6R33pQ+/uvt2yEij6dlshGRJt6oYLeILEnD/FIdQFU/VdUkVT2gqlNV9XcRqQUMA5p6T9G707sGb38vEflLRBJEZJmINAgiX00RWSci16T32arqcmA2UNc7dr2IPCgivwP7RCRf4GchInlF5BERWePJ8JuIVAjo93tvpLRCRK5Or39Php3A+AAZPhSRoSIyRUT2AW1EpKCIDBSRjSKyzTMbFQ645gEislVEtojILSd8Hh+KyLMB611FZLGI7PGuo5OIPAe0BN7yvo+3vLaBpqq0fl83ichPnoy7vM//4lCu35EFqKpbTtMF6AQkAvnSaTcS+BI4A6gErARu9fbdAqwGzgeKAROAj719tYG9QAtsNDIQOAK08/Y/BYzy3pcDdgCXYA8u7b31MkHkOdPb9xFwMVDyhP03AT9l4Bq6A38DjQABqgIVvX3rgXZAA2Aj0DmNz0mBqgHX/k9AH+uBxUAFoHDgub33A4A/gBqeDFFAKaAosAm4GcjnybEdqJOKDDOB27z3pYHpAd/Hh0A8NjrMAxQCXgcmYSOxM4DJwAsBv49tmIIpCnxywjV+CDzrvW/snbu9d+5yQM0TZUrls0rru7kJ+830AvICfYEtgPj9/zkdFt8FcIuPXz7cAPxzwra5wG7gABDr/SkPAbUD2vQBZnrvf8BGICn7anh/6HzAE8CnAfuKAIcJriAeTLmRBbT/DuiZiuy1vBvUZkzJTQLKevtuIkBBhHAN3wF3p9LPesx8tRlok87nqcAeYBewBngWyBNwnluCnDvls1gBdA1yzh7A7BO2vQM8mYoMM4H93nf4NzAaT8l6n9fIgLYC7AOqBGxrCqzz3r8PvBiwrzqpK4h3gEFpyBRUQYTw3dwErD7hN6TA2X7/f06HJdy2UEdkswMoLSL5VDURQFWbAYjIZuxJsDT29L8h4LgN2BMiwLlB9uXDfBnnYk+/eOfeLyI7UpGlItBdRC4L2JYfmBGssar+hd08EJGawCjsafjaIM3Tu4YK2A09NW4HflTVoLKcQANVXZ3Kvk2pbE9LhorAhSmmMo98wMdpnKu/qr4XggxlsBvub3IsHkGwmzbY9/dbQPvAz+9EKgBT0tifGul9N2AjMeDobwhstOoIM84HcXrzM/b01jWNNtuxEUHFgG3nYU+nYMP9E/clYqaJrUD5lB2ebbtUKv1swkYQJQKWoqr6YnoXoWbv/xDP1o49YWbkGjYBVdLo4nbgPBEJ6uzNAGmVTk5Nhk2Ycgr8XIqpat8skGE7NlKsE3Du4moObrDvr0JA+/MyIf+JfZ5Iet+Nw0ecgjiNUdXdmPnkbRHpJiLFPKdzNGZzRlWTgM+B50TkDBGpCPwPe2IH+BS4V0Qqi0gx4HlgjDciGQdcJiLNRKSA11dqobOjvLYdPYdtIRFpLSLlT2zoOW3vS9nnOXOvBeZ5TbYB5b0+Q7mG94D7RaShGFW9NikkYPb4WBFJV2FlkveA/xORap4MF4hIKSxaq7qI3Cgi+b2lkeeMPyVUNRl4FxgkIv8BEJFyItLRa/I5cJOI1BaRIsCTaZxuBHCziLT1fkPlvJEd2PcRNOchhO/G4SNOQZzmqOrL2B/yAeBf7M/8DuYTmOs1uwuzVa8FfsKcle97+97HzB2zgHXAQa89qvqn9/4z7Gk0wevjpHBUVd2EjWQeAeKwJ9IBBP+NJgAXAr940TjzgKXAfd7+6cCfwD8isj29a1DVscBz3rYEYCLmtA2UbzfmgL1YRNKN/c8Er2E3yqmYH2ME5sxOADoA12CjtX+Al4CCWdTvg1iQwTwR2QNMw/xIqOo3mNluutdmemonUdVfMUf6IMxZ/SPHRgVvAN28KKQ3gxye1u/L4SPiOX4cjrDjjTB2A9VUdZ3f8jgcjrRxIwhHWBGRy0SkiIgUxcJc/8CidxwOR4TjFIQj3HTFTCNbgGrANeqGrQ5HjsCZmBwOh8MRFDeCcDgcDkdQwpooJyL3ArdhcdB/ADer6kFv32BvvZi3XhBLuW+IJXD1UNX1aZ2/dOnSWqlSpbDJ73A4HLmR3377bbuqlkmvXdgUhIiUA/pjKfQHRORzLFTvQxGJwapMBnIrsEtVq4oVQ3sJKzOQKpUqVWLBggVhkN7hcDhyLyKSVlb8UcJtYsoHFBYrb1wE2CJWYvgVLO4+kK5Y8TWwBKu2IpE7H4HD4XDkdsKmIFT1byyscSOWJBWvqlOBfsAkVd16wiHl8OrEeFm48QQpyyAivUVkgYgsiIuLC5f4DofDcdoTNgUhIiWxUUFlrOhXURH5L1ZaeXCwQ4JsOynESlWHq2qMqsaUKZOuCc3hcDgcmSScTup2WNngOAARmYDV4ikMrPasR0VEZLWqVsXKKVcANnsmqeLAzox2euTIETZv3szBgwez6DIcDn8oVKgQ5cuXJ3/+/H6L4jhNCaeC2Ag08Yp8HcCmYHxNVY+OHkRkr6ccwOr598QqjHYDpmcmoWrz5s2cccYZVKpUCefCcORUVJUdO3awefNmKleu7Lc4jtOUcPogfsGczQuxENc8wPA0DhkBlBKR1VjxuIcy0+/BgwcpVaqUUw6OHI2IUKpUKTcSdvhKWPMgVPVJ0igRHFB3Hi8/ontW9OuUgyM34H7HDr9xmdQOh+P0QhVGj4alS/2WJOJxCiIM5M2bl+joaOrWrctll13G7t270z8oFSpVqsT27dtP2r5371769u1LlSpVqF+/Pg0bNuTdd989FbGD0rp16wwlI86bN48LL7yQ6OhoatWqxVNPPQXAzJkzmTt3btoHp8L69eupW7duum0KFy5MdHQ0tWvX5vbbbyc5OTlo22bNmmVKDkcuYfJkuOEGqF8fHn8cnBkvVZyCCAOFCxdm8eLFLF26lLPOOoshQ4ZkeR+33XYbJUuWZNWqVSxatIhvv/2WnTszHPSV5fTs2ZPhw4cfvf6rr74aODUFESpVqlRh8eLF/P777yxbtoyJEycetz8pKQkg7HI4IpiDB+Gee6B2bbjuOnj2WYiOhlmz/JYsInEKIsw0bdqUv/8+Nr3uK6+8QqNGjbjgggt48slj7pnLL7+chg0bUqdOHYYPT8uXD2vWrOHXX3/l2WefJU8e+wrLlCnDgw8+CFgEzIABA6hbty716tVjzJgxaW5PTk7mjjvuoE6dOnTu3JlLLrmEcePGndTv1KlTadq0KQ0aNKB79+7s3bv3pDb//vsv55xzDmAjqdq1a7N+/XqGDRvGoEGDiI6OZvbs2WzYsIG2bdtywQUX0LZtWzZu3AjAtm3buOKKK4iKiiIqKuqkm/natWupX78+8+fPT/XzyZcvH82aNWP16tXMnDmTNm3acN1111GvXj0AihU7Nt/9yy+/TL169YiKiuKhhx46+vl26tSJhg0b0rJlS5YvX57m9+HIQbzyCqxbB4MHw0cfwXffweHD0KoV9OkDpzDaz5Woao5dGjZsqCeybNmyYyt3363aqlXWLnfffVKfJ1K0aFFVVU1MTNRu3brpN998o6qq3333nfbq1UuTk5M1KSlJL730Uv3xxx9VVXXHjh2qqrp//36tU6eObt++XVVVK1asqHFxcced/8svv9TLL7881f7HjRun7dq108TERP3nn3+0QoUKumXLllS3jx07Vi+++GJNSkrSrVu3aokSJXTs2LGqqtqqVSudP3++xsXFacuWLXXv3r2qqvriiy/q008/fVLfTz/9tJYoUUIvv/xyHTZsmB44cEBVVZ988kl95ZVXjrbr3Lmzfvjhh6qqOmLECO3atauqql599dU6aNCgo5/f7t27dd26dVqnTh1dvny5RkdH66JFi07qN6WNquq+ffs0JiZGp0yZojNmzNAiRYro2rVrT/p+pkyZok2bNtV9+/Yd9x1cdNFFunLlSlVVnTdvnrZp0ybVzzrcHPd7dpwa69apFiqk2r378dv37lW97z7VPHlUzzlHdfx4X8TLToAFGsI91o0gwsCBAweIjo6mVKlS7Ny5k/bt2wP2BD516lTq169PgwYNWL58OatWrQLgzTffJCoqiiZNmrBp06aj20PhueeeIzo6mnPPPReAn376iWuvvZa8efNStmxZWrVqxfz589Pc3r17d/LkycPZZ59NmzZtTupj3rx5LFu2jObNmxMdHc1HH33Ehg0n1/t64oknWLBgAR06dOCTTz6hU6dOQWX++eefue666wC48cYb+emnnwCYPn06ffv2BWwEUrx4cQDi4uLo2rUro0aNIjo6Oug516xZQ3R0NM2bN+fSSy/l4osvBqBx48ZBcwmmTZvGzTffTJEiRQA466yz2Lt3L3PnzqV79+5ER0fTp08ftm49sSqMI0dy332QJw8MHHj89qJFbduvv0LZsnDVVXDllbBliz9yRhBhDXP1nddf96XbFB9EfHw8nTt3ZsiQIfTv3x9V5eGHH6ZPnz7HtZ85cybTpk3j559/pkiRIrRu3TrN+PfatWuzZMkSkpOTyZMnD48++iiPPvroUdOJppJfmNHtJ7Zp3749n376abptq1SpQt++fenVqxdlypRhx44d6R6TXkhn8eLFqVChAnPmzKFOnTqp9rt48eKTthctWjRoe1U9qd/k5GRKlCgR9DyOHMz338OECeZzOO+84G0aNjQl8dpr8NRTUKsWvPQS9O5tiuU05PS86myiePHivPnmmwwcOJAjR47QsWNH3n///aO2+7///pt///2X+Ph4SpYsSZEiRVi+fDnz5s1L87xVq1YlJiaGxx577Kjj9eDBg0dv9LGxsYwZM4akpCTi4uKYNWsWjRs3TnV7ixYtGD9+PMnJyWzbto2ZM2ee1GeTJk2YM2cOq1evBmD//v2sXLnypHZff/31UTlWrVpF3rx5KVGiBGeccQYJCQlH2zVr1ozPPvsMgNGjR9OiRQsA2rZty9ChQwFzKu/ZsweAAgUKMHHiREaOHMknn3wS2heQDh06dOD9999n//79AOzcuZMzzzyTypUrM3bsWMCUyJIlS7KkP4dPHD4M/ftDlSo2ikiL/PnhwQfhjz8gJgb69jX/xOnqhwrFDhWpS7o+CJ9IsXGn0LlzZx05cqSqqr7++utat25drVu3rjZp0kRXr16tBw8e1E6dOmm9evW0W7du2qpVK50xY4aqBvdBqKrGx8dr7969tVKlStqgQQNt3ry5Dh48WFVVk5OT9f7779c6depo3bp19bPPPktze1JSkvbp00dr1aqlXbt21U6dOunUqVNV9ZgPQlX1hx9+0JiYGK1Xr57Wq1dPv/zyy5Pk6tGjh1arVk2joqK0YcOG+u2336qq6ooVK7RevXoaFRWls2bN0nXr1mmbNm20Xr16etFFF+mGDRtUVfWff/7RLl26aN26dTUqKkrnzp17nH9h165dGhMToxMnTjyu38A2gcyYMUMvvfTSVL+fF154QWvVqqVRUVH68MMPq6rq2rVrtWPHjnrBBRdorVq1gvpasotI+D3neF55RRVUv/oqY8clJ6u+/75qyZKqBQqoPvOM6qFD4ZExmyFEH0SOnpM6JiZGT4zR/+uvv6hVq5ZPEuVc9u7dS7FixdixYweNGzdmzpw5nH322X6Lddrjfs+nyNatUL26jQK++ipz59i2De6+G8aMgTp14L33oEmTrJUzmxGR31Q1Jr12zsTkAKBz585ER0fTsmVLHn/8caccHLmDBx4wE9Op+CPLloXPPrMEu/h4aNYM7roLPNNkbiZ3O6kdIRPM7+Bw5Gh++glGjYJHH4WqVdNvnx6dO9tI5NFHLY+iVClzZudi3AjC4XDkPpKSoF8/qFABHn446857xhnw5ptw4YXwww9Zd94IxSkIh8OR+3jnHViyBF591fIcsprYWAuJPXAg688dQTgF4XA4chfbt8Njj8FFF0G3buHpIzbWfBu//hqe80cITkE4HI7cxaOPwp49ZgoK15wazZvbuXN5kT+nIMJAYLnv7t27H03EygwzZ86kc+fOAEyaNIkXX3wx1ba7d+/m7bffznAfTz31FANPLD/gMWrUKC644ALq1KlDVFQUt9122ymVLw/Ghx9+SL9+/UJuv3//fq6//nrq1atH3bp1adGiBXv37s309acQSmnz1q1bU6NGDaKiomjevDkrVqwI2u6JJ55g2rRpmZbFkUkWLIB337XEuFQy7rOEkiXhggucgnBknMBy3wUKFGDYsGHH7VfVVOcqSIsuXbocrTgajFO9QZ7It99+y6BBg/jmm2/4888/WbhwIc2aNWPbtm1Z1kdmeOONNyhbtix//PEHS5cuZcSIEeTPnz/Lrz81Ro8ezZIlS+jZsycDBgw4aX9SUhLPPPMM7dq1C7ssjgCSk80x/Z//wJOpTmSZdcTGwty5cORI+PvyCacgwkzLli1ZvXo169evp1atWtxxxx00aNCATZs2pVo++9tvv6VmzZq0aNGCCRMmHD1X4JN2sLLYDz300NGCdSk3rtTKiz/33HPUqFGDdu3apfoU/NxzzzFw4EDKlSsH2MjolltuoUaNGgD88MMP1K9fn3r16nHLLbdw6NChNLdPmTLl6HX179//6MgokLi4OK666ioaNWpEo0aNmDNnzklttm7delQmgBo1alCwYMGTrl9TKW8Owct8p5CcnEzPnj157LHHgn4uKcTGxh4tPVKpUiWeeeYZWrRowdixY7npppuOlkyfP38+zZo1IyoqisaNG5OQkEBSUhIDBgw4+t288847afblCIGRI+GXX6x+klfkMazExlouxMKF4e/LJ3J1HsQ990BW11yLjg495yYxMZFvvvnmaEXTFStW8MEHH/D222+zfft2nn32WaZNm0bRokV56aWXeO2113jggQfo1asX06dPp2rVqvTo0SPoufv370+rVq344osvSEpKYu/evbz44ossXbr0aKG5qVOnsmrVKn799VdUlS5dujBr1iyKFi3KZ599xqJFi0hMTKRBgwY0bNjwpD7+/PNPGjRoELT/gwcPctNNN/HDDz9QvXp1/vvf/zJ06FBuv/32VLf36dOHWbNmUblyZa699tqg57377ru59957adGiBRs3bqRjx4789ddfx7W55ZZb6NChA+PGjaNt27b07NmTatWqnXT948ePZ/HixSxZsoTt27fTqFEjYmNjWbx4MRMnTuSXX36hSJEix020lJiYyPXXX0/dunV59NFH0/x+J0+efHSOCYBChQodrUr77bffAnD48GF69OjBmDFjaNSoEXv27KFw4cKMGDGC4sWLM3/+fA4dOkTz5s3p0KFD0KqzjhDYvdtqKDVtCjfemD19tmxpr7NmWdhrLiRXKwi/SCn3DTaCuPXWW9myZQsVK1akiZeiH1g+G+xG0rRpU5YvX07lypWpVq0aADfccEPQCYSmT5/OyJEjgWNlsXft2nVcm8Dy4mDlNFatWkVCQgJXXHHF0TLXXbp0Sfea/vjjD2688UYSEhJ4/vnnqVmzJpUrV6Z69eqAzSQ3ZMgQ2rRpE3R769atOf/884/eAK+99tqg1zVt2jSWLVt2dH3Pnj0kJCRwxhlnHN0WHR3N2rVrmTp1KtOmTaNRo0b8/PPPFC5c+LhzpVbe/McffzypzHcKffr04eqrr05TOVx//fUULlyYSpUqMXjw4KPbgynzFStWcM4559CoUSMAzjzzTMC+m99///3oKCM+Pp5Vq1Y5BZFZnnoK4uLgm2+yr/Jq2bJWxmP2bAhiaswN5GoF4VO176M+iBMJLDutqZTPXrx4cbqlr0NFUykv/vrrr4fUR506dVi4cCFt2rShXr16LF68mH79+nHgwIGwlBQHM+8Eu9mfSLFixbjyyiu58soryZMnD1OmTOGqq64KWZbUrr9Zs2bMmDGD++67j0KFCgVtM3r0aGJiTi5jE6yseGp9qSqDBw+mY8eOQftwZIClS+Gtt6wsdyoj3rARGwvjxpn/IxeWBM99V5RDSK18ds2aNVm3bh1r1qwBSHX+hWBlsU8sqZ1aefHY2Fi++OILDhw4QEJCApMnTw7ax8MPP8z999/P5s2bj2474CUG1axZk/Xr1x+V/+OPP6ZVq1Zpbl+7di3r168HOM4fEEiHDh146623jq4HU7Rz5sw5Olo6fPgwy5Yto2LFiiddf2rlzYOV+U7h1ltv5ZJLLqF79+4kJiYGlTEj1KxZky1bthydIjUhIYHExEQ6duzI0KFDOeI5OFeuXMm+fftOub/TDlWri1S8ODz3XPb3Hxtr5q2lS7O/72wgV48gIpkyZcrw4Ycfcu211x514j777LNUr16d4cOHc+mll1K6dGlatGjB0iA/vjfeeIPevXszYsQI8ubNy9ChQ2natCnNmzenbt26XHzxxbzyyiv89ddfNG3aFLCn7lGjRtGgQQN69OhBdHQ0FStWpGWKLfUELrnkEuLi4rj44otJSkqiRIkS1K1bl44dO1KoUCE++OCDozfSRo0acfvtt1OwYMFUt7/99tt06tSJ0qVL07hx46B9vvnmm9x5551ccMEFJCYmEhsbe1IU2Jo1a+jbt+/RaLBLL72Uq666ChE57vpffvllfv75Z6KiohARXn75Zc4++2w6derE4sWLiYmJoUCBAlxyySU8//zzR8//v//9j/j4eG688UZGjx59dN7vzFCgQAHGjBnDXXfdxYEDByhcuDDTpk3jtttuY/369TRo0ABVpUyZMkycODHT/Zy2fP45zJwJQ4dabaTsJjbWXmfNsrDXXEZYy32LyL3AbYACfwA3A0OAGECAlcBNqrpXRAoCI4GGwA6gh6quT+v8rtx3ziKlpLiqcuedd1KtWjXuvfdev8WKaNzvOQ327rVZ38qUgfnzIW9ef+SoWNGc1J9/7k//mcD3ct8iUg7oD8Soal0gL3ANcK+qRqnqBcBGICVD6lZgl6pWBQYBL4VLNoc/vPvuu0RHR1OnTh3i4+NP8o04HBni+edh82arrOqXcgAbRcyaZeauXEa4fRD5gMIikg8oAmxR1T0AYp67wtjoAqAr8JH3fhzQVrLKW+uICO69914WL17MsmXLGD169NEoIocjw6xaBQMHwn//a2Uv/CQ21iYVWrXKXznCQNgUhKr+DQzERglbgXhVnQogIh8A/wA1gZQ4wXLAJu/YRCAeOMmoKCK9RWSBiCyIi4tLre+svRiHwwfc7zgVVC3JqVAhS4rzm0A/RC4jnCamktiooDJwLlBURG4AUNWbvW1/ASnB48FGCyf9Q1R1uKrGqGpMmTJlTjqgUKFC7Nixw/25HDkaVWXHjh2phtqe1owZA1OmWO5DJMx8WL26lffIhQoinFFM7YB1qhoHICITgGbAKABVTRKRMcAA4ANgM1AB2OyZpIoDO4OdOC3Kly/P5s2bSW104XDkFAoVKkT58uX9FiOy2LbN6i1deKHNEx0JiBzzQ+QywqkgNgJNRKQIcABoCywQkaqqutrzL1wGLPfaTwJ6Aj8D3YDpmolhQP78+V02qsORW+nXDxIS4P33/XVMn0hKwtyGDRbVlEsIm4JQ1V9EZBywEEgEFgHDgekiciZmUloC9PUOGQF8LCKrsZHDNeGSzeFw5EDGjrWb8AsvQO3afktzPCl+iNmzc5WCCGseRLgJlgfhcDhyIXFxphQqVYKff4Z8EZbjm5QEpUtD9+4QpMZYpOF7HoTD4XBkGf36QXw8fPBB5CkHMHNXixa5zg/hFITD4Yhsxo+3LOUnn4S6df2WJnViY2HFCnOk5xKcgnA4HJHL9u1wxx1WpfWBB/yWJm0C/RC5BKcgHA5H5NK/P+zaZaal/Pn9liZtGjSAIkVylZnJKQiHwxGZTJwIn34Kjz2WMyql5s8PzZo5BeFwOBxhZedOuP12m+P34Yf9liZ0YmPh999t1JMLcArC4XBEHnffDTt25AzTUiCxsVYras4cvyXJEpyCcDgckcXkyTBqFDzyiI0gchKNG5tCyyVmJqcgHA5H5LBrF/TpA/XqwaOP+i1Nxilc2JSEUxAOh8ORxdx7L/z7L3z4IRQo4Lc0mSM2Fn77DXLBHONOQTgcjsjg66/ho4/MKd2ggd/SZJ7YWEhMhHnz/JbklHEKwuFw+M/u3WZaqlPHwlpzMs2aQZ48ucLMFIFFTRwOx2nHfffBP/9Y7kPBgn5Lc2qceSbUr58rFIQbQTgcDn/59lub3+GBByAm3QKjOYPYWDMxHTrktySnhFMQDofDP+LjoVcvqFULnnjCb2myjthYOHgQcvh0BE5BOBwO/xgwALZssYS43DT/dosW9prDzUxOQTgcDn/4/nt49124/36bYzo3Ubq0OdydgnA4HI4MkpAAt90GNWvC00/7LU14iI21khuJiX5LkmmcgnA4HNnPAw/Apk3mnM5NpqVAYmNNES5ZctKuuDibpTTQFfgPAAAgAElEQVTScQrC4XBkL+vXw7BhVpCvaVO/pQkfLVvaa4CZKTkZXnsNypWz6auTk32SLUScgnA4HNnLhAn2etdd/soRbsqVgypVjiqIf/+Fzp0t5aN2bfjii8jPCXQKwuFwZC8TJliV1vPP91uS8BMbC7Nn88P3yURFwfTpMGQILFpk0b0vvAAff+y3kKnjFITD4cg+tm6FuXPhyiv9liRbONKsFY/s+B/tOwolS8Kvv9oU2yLw1lvQurX56ufO9VvS4KSrIESkrIiMEJFvvPXaInJr+EVzOBy5ji++sAl1rrrKb0nCzvr1EPt2D17gEW5t9hfz5x8/c2qBAjBuHFSoAJdfDhs2+CZqqoQygvgQ+A4411tfCdwTyslF5F4R+VNElorIpyJSSERGi8gKb9v7IpLfaysi8qaIrBaR30UkB5dzdDgcQZkwAWrUsMzpXMzYsWZFW7amIJ+V7Mu7Ff6PokVPbleqFHz1FRw+DJddZkFPkUQoCqK0qn4OJAOoaiKQboCWiJQD+gMxqloXyAtcA4wGagL1gMLAbd4hFwPVvKU3MDRDV+JwOCKbHTtg5kwbPYj4LU1Y2L8feveGq6+2FI/Fi4UeneLNUa0a9JiaNU2hLFsG110XWeGvoSiIfSJSClAAEWkCxId4/nxAYRHJBxQBtqjqFPUAfgXKe227AiO9XfOAEiJyTkYuxuFwRDCTJtndL5eal/74Axo1gvfeg4cegtmzoXJlzFG9ZQusXZvqse3bwxtv2Gji4YezT+b0CEVB/A+YBFQRkTnASCDd+DRV/RsYCGwEtgLxqjo1Zb9nWroR+NbbVA7YFHCKzd624xCR3iKyQEQWxMXFhSC+w+GICMaPh0qVrBR2LkIVhg61mUZ37oTvvrPopPz5vQaxsfaaTtmNO+80B/Yrr1hpqkggXQWhqguBVkAzoA9QR1V/T+84ESmJjQoqY/6LoiJyQ0CTt4FZqjo75ZBg3QeRZ7iqxqhqTJkyZdITw+FwRAJ79ljtpSuvzFXmpV27oFs3u7G3bm1J0+3bn9CoVi1zNoRQl+n116FdO5s7afbsdJuHnVCimO4Eiqnqn6q6FCgmIneEcO52wDpVjVPVI8AETMkgIk8CZbDRSQqbgQoB6+WBLaFdhsPhiGi+/to8sbkovPWnnyAqCiZPhoED7RL/858gDUUsqzoEBZE/P3z+uZmmrrgiTatUthCKiamXqu5OWVHVXUCvEI7bCDQRkSIiIkBb4C8RuQ3oCFyrqoGJ5pOA/3rRTE0wk9TWkK/E4XBELhMmwNln55rSGi++CK1aWajq3LmWHZ0nrbtpbKzd7TdvTvfcJUuaLyI52SKb9uzJOrkzSigKIo93gwdARPICBdI7SFV/AcYBC4E/vL6GA8OAssDPIrJYRFJmCZkCrAVWA+8CoYxSHA5HpLN/P0yZYo/Ead5FcwZTppgjuVs3WLgwxEnwUvwQIdqNqlWzHImVK+Gaa/yLbBJNJfTqaAORV4BK2I1dgduBTap6X9ilS4eYmBhdkMNnbHI4cj0TJ5pymDYN2rb1W5pTYt8+m+ahaFErl1Eg3Udlj8REOOssuOEGePvtkPt75x24/Xa45x4YNChzMgdDRH5T1XRVW74QzvUg5pzuizmSpwLvnZp4DofjtGH8eLs5pjxF52CeftoynmfPzoByAMiXD5o3z/AEQn36WH7E66+br7t374zJe6qEEsWUrKpDVbWbql6lqu+oagSlcjgcjojl8GHz4nbtGhD3mTNZssRKdffqdWxG0QwRGwt//gnbt2fosFdfhU6dLAx2xoxM9HsKpKogRORz7/UPr/TFcUv2iehwOHIs06dDfHyOj15KSrKn91Kl4KWXMnmSlBHUTz9l6LB8+eCzz8wvcdVVsGpVJvvPBGmZmO72XjtnhyAOhyMXMn48nHFGkOSAnMWwYVaJ9ZNPLMooU8TE2Ox5s2ZZdb4MULy4DcQuvNAim+bNgxIlMilHBkh1BKGqW72IpRGquuHEJfyiORyOHE1SkjmoO3eGggX9libTbNliUUsdOlhEUaYpWBCaNMmwHyKFKlUsWnjtWqv1lB1TXafpg/B8DftFpHj4RXE4HLmK2bPN3p7DzUv9+8ORIxZ8dMpJ4LGxFv6UyeSG2Fgr6/H999lTsymUKKaDwB8i8j2wL2WjqvYPm1QOhyPnM2GCmVQuvthvSTLN5MlmJXv+eXuCP2ViYy0Dbu5c8zxngltvtZpPnbPB+B+KgvjaWxwOhyM0kpNNQXTqRNCJEHIAe/dCv35Qty7cf38WnbRJE/M6z5qVaQUBMGBAFsmTDmkqCBGpj40a/lTVv7JHJIfDkeOZPx/+/ttqUuRQnnwSNm6EOXOyMEK3aFFzVmfSD5HdpBXm+gQwBrgK+FpEQqm/5HA4HGaXyZ8/e+wgYWDRIktO69MHmjXL4pPHxlpI1IEDWXzirCctJ3UPIFpVrwUaYbO8ORwOR9qomnmpbdvsicXMYlJyHsqUCdMAKDbWvN6//BKGk2ctaSmIg6q6H0BVd6TT1uFwOIzff4c1a3Js9NKQIbBggc3wFhb91ry5hUPNnBmGk2ctad30q4jIJG+ZfML6pOwS0OFw5DDGj7eqrRlMBosENm+GRx81//HVV4epkxIlzA8xbVqYOsg60nJSdz1hfWA4BXE4HLmECRPMjJIDZ3zs399MTFmS85AW7dtbzY74eEuTjlBSVRCq+mN2CuJwOHIBK1ZYQbo33/Rbkgzz5ZfwxRd2365cOcyddehgyRUzZkT0SMv5FRwOR9YxYYK9XnGFv3JkkIQEy3moVw/uvTcbOmza1EJev/8+GzrLPKEkyjkcDkdojB9vFeXKl/dbkgzxxBOWtjF2bDZVJS9QANq0galTs6GzzJPuCEJEKgXZ1igcwjgcjhzMhg3w229WkzoH8dtvZhHr29cSnbONDh1g9WqrvhehhGJimiAi5VJWRKQV8H74RHI4HDmSFPNSDgpvTUy0nIf//MdcAtlKSgn0CDYzhaIg+gATReRsEbkEeAO4JLxiORyOHMeECRAVlUVV7bKHt96ChQttBJHtwUQ1akCFChFtZgplytH5QH9sLuqngPaquinMcjkcjpzEP/9Y0aIcNHrYtAkeewwuvRS6dfNBABEzM02fnj2TO2SCtGoxTQ5IinsYKAIcAka4RDmHw3EcX3xhJTZyiP9B1aKWVG0UEdach7To0AF277bU7QgkrSgmlxjncDhCY8IEqF4datf2W5KQmDgRJk2CV16BSpV8FKRtW9NOU6dms4c8NNKacvRHL1luI/BLwPqvgJty1OFwGDt2WMLXVVf5+CgeOvHxcNdd5i65+26fhSlVCho2jFg/RChO6rFAcsB6krctXUTkXhH5U0SWisinIlJIRPqJyGoRUREpHdBWRORNb9/vItIgY5ficDh8YfJkq0+RQ8xLDz4IW7fC8OHZlPOQHh06wLx5prkijFAURD5VPZyy4r0vkN5BXmhsfyBGVesCeYFrgDlAO04ehVwMVPOW3sDQUC7A4XD4zPjxULEiNIj8Z7qZM+GddyxbunFjv6Xx6NDBFGwEVncNRUHEiUiXlBUR6QpsD/H8+YDCIpIPc3JvUdVFqro+SNuuwEg15gElROScEPtxOBx+kJBg5pErr4x489L+/dCrF5x/PjzzjN/SBJBSdiMCzUyhlNq4HRgtIkO89U3AjekdpKp/i8hAzIdxAJiqqml9AuW8c6ew2du2NbCRiPTGm7zovPPOC0F8h8MRNr7+Gg4fzhHhrU89ZYnL06dDkSJ+SxNABJfdCCUPYo2qNgFqAbVVtZmqrknvOBEpiY0KKgPnAkVF5Ia0DgnWfRB5hqtqjKrGlMmB5YQdjlzFhAlw9tlhmJcza1mwAF591UYQbdr4LU0Q2rePyLIbodRiKi4irwEzgRki8qqIhJJz2A5Yp6pxqnoEmACk9SvaDFQIWC8PbAmhH4fD4QcHDsCUKVauOk/kFoY+fBhuucX02Msv+y1NKnToYK8RVnYjlG/1fSABuNpb9gAfhHDcRqCJiBQREQHaAn+l0X4S8F8vmqkJEK+qW9No73A4/GTqVNi3L+Kjl15+Gf74A4YOjeApslPKbuRABVFFVZ9U1bXe8jRwfnoHqeovwDhgIfCH19dwEekvIpuxEcLvIvKed8gUYC2wGngXuCPjl+NwOLKN8eOhZElo1cpvSVJl2TL4v/+DHj2gS5f02/tGStmNH36IqLIboSiIAyLSImVFRJpjTud08RRLTVWtq6o3quohVX1TVcuraj5VPVdVb/PaqqreqapVVLWeqkZm7rnD4TC7zaRJ0LVrhCQTnExSEtx2GxQrlkMmuGvfPuLKboQaxTQywO+wC+gZPpEcEU1cnEWuLFoEN90E9ev7LZHDD2bMsMSuCDYvDRkCP/8MH39s5bwjnggsuyGqJwUKHd9ApLKqrhORMwFUdU/KtmyRMA1iYmJ0QQRp21yJqs0xPHmyLfPm2bY8eey1Tx949lkrGRCpHDgAO3fCrl32unOn3dzOPBPKlLG7R5kyZqCO8Fj+iKF3b/j0U3tgKFTIb2lOYv16qFPHrF9ff52DvtZGjaBgQfjpp7B2IyK/qWpMeu1CGUGMBxqo6p6AbeOAhpkVzhHhHD4Ms2aZCeGrr2Cd9yzQsCE8+SRcdpnN6v7001YKc8wYUxJ9+kDevOGXLynJHg23bj12w09rOXgwtPPmywelS5uyCLakKJIyZaBsWTjrrPBep1+owp49aX+m48ZB584RqRxUTX/lyQPDhuUg5QDmh3jpJfv8zzzTb2lSVxAiUhOoAxQXkcAsmDOByPtVOE6NHTssZHHyZPjuO/uBFioE7drBQw9Z0fxy5Y4/5vXXzcjbvz/ceacVtxk8GFq2DI+MCQnw/vtmUD4xXrxwYbthpyzVqh2/ftZZ5lBNeX/mmTaKiItLfVm40F537w4uT9WqZhZo29aC60uXDt4u0lizxhzMf/8d/Oa/a5cp4dQoWtSutU+f7JM5A3z0kQUDDRkCOS6XtkMHm9puxgzz7/hMqiYmr6TG5UAXLAQ1hQTgM1WdG37x0saZmE4BVVi+/JjpaO5cSE62YPHLLrOlbdvQUk5V7YnyvvtsFpbrrrPYwhMVSmZZv94Uz3vvmeJq1szKcdate+zGX7hw1vQVjCNHYPt2+PffY8pj82aYPdvq5yQk2GNqVNQxhdGypXlHI4Xdu2HsWLt7zplj24oXP1mJpreULGkmkAjln3+gVi37afz4Y0SnZwTn8GH7nHv2NA0XJkI1MaGqaS5A0/Ta+LU0bNhQHZlg/XrVWrVU7dauGh2t+vjjqr/+qpqUlPnz7t1r5ylYULVoUdUXX1Q9eDBz50pOVp0zR7VbN9U8eVTz5lW95hrVX37JvHzh4MgR1blzVf/v/1Rbt1YtUMA+03z5VFu0UH3ySdVZs1QPHfJHtq+/Vu3Rw74TUK1ZU/WFF1Q3bsx+ebKBq66yS12+3G9JToFLL1WtWjWsXQALNIR7bFqKoRdQzXsvWMJcPPA75pNwCiKn0q+f3ciGDAnPjWLNGtWuXe3nVa2a3aRC5fBh1U8/VW3c2I4vUUL1gQdyzg1t3z7VqVNVH3xQNSZGVcSuo2hR1U6dVF95RXXhwlNTxOmxZInq//6nWras9V2qlH3nv/5qijeXMm6cXe4LL/gtySnyxht2IWvXhq2LrFAQS4H83vvrgN+AUlgJjdmhnDzci1MQmWDXLrtZ9ewZ/r6++Ua1enX7mXXurLp6deptd+5Ufekl1fLljymWt95STUgIv5zhZOdO1QkTVO+8057eU0ZtZ52l2rKl6i23qD7/vOrYsaqLFmX+ev/5R/XVV1Wjouz8+fOrXn656hdf+DN6yWZ27jR9WL++PWPkaP76y77Dd94JWxdZoSAWB7z/BLg7YH1hKCcP9+IURCZ49VX72hcuzJ7+Dh1Sffll1WLFbNTyyCNmikphxQrVO+5QLVLE5LroItXJk8P7hO0nmzerjhypeuutZoI6++xjSiNlOfts23fzzarPPaf6+ef2fe3Zc/y5DhxQHTNG9ZJLzAQHqo0amWKNi/Pn+nzi5pvtI8iun3VYSU5WrVDB7GVhIlQFkZaTeiFwKZYYtwG4SFX/9Pb9paq1MuATCQvOSZ1BkpIs8ua888yDl51s2WJTeY0aBeXLw4ABFmry9deWiXvddXDPPeboPd1ISLDIolWrrKLn6tXH3m89oRxZ2bL2HZYta2UZ4uPt87zxRltq+f63zHa+/96Cfx5+2AKAcgW33mqVcuPiLPw6iwnVSZ2WgugMvIPNBDdZVXt521sBD6jqpVkob6ZwCiKDfPGF1e0fP96/+v1z5kC/frB4seUT9O1ry9ln+yNPpLN3rymPQKWxejVs3AgtWli0S+vW2ZN/EoHs3Qv16tmUCkuWRGRaRuYYMwauucbyfcKQVX3KiXKq+pWIVATOUNVdAbsWAD2yQEZHdvPGG1Cpkr/x1c2bW62ZhQvtn51r/tFholgxG1WdjiOrEHjsMYuCnjUrl/2UIqTsRppRwqqaeIJyQFX3qere8IrlyHIWLzazUr9+/j9t5s1rJQVy1T/akd38/LPlTN5xR/hyM32jdGmrXOBz+e+clkbiyCxvvGEZsLfe6rckDscpc+iQ/ZTLl4cXXvBbmjDRoYNpwT170m8bJpyCOB3Ytg0++cSqr0bsjCkOR+g89xz89ZfVWoqAkkXhoX17CyyZMcM3EUKZclRE5AYRecJbP09EGodfNEeW8c47lsLfv7/fkjgcp8zkyRatdP31cMklfksTRpo2tVH/1Km+iRDKCOJtoClwrbeeAISvSIgjazl0CN5+2/5J1av7LY3DcUp8/z1062bm+bff9luaMFOwoEWoRbiCuFBV7wQOAnhO6wJhlcqRdXz+uZmY7rnHb0kcjlNi9mwLwKtZE775JheblgLp0MHCmlNK7mczoSiIIyKSF7CiTCJlgOSwSuXIGlRh0CCoXdvKdjscOZT5863i/Hnn2Sgit07FcRLt29urT9FMoSiIN4EvgP+IyHPAT0BuyVfM3fz0k00NevfdOWzWFIfjGL//Dh07WuTnDz/kkOlDs4qaNS1UyyczU7o53Ko6WkR+A9piVV0vV9W/wi6Z49R54w171LrhBr8lcTgyxfLl9hBdtKgph6yaYiTHIGJmpgkTLKIpm3OYUh1BiMhZKQvwL/ApVrRvm7fNEcmsX2+lNXr3Dm3SH4cjwli37phldNo0m+X2tKRDB5vwyYeyQmmNIH7D/A6BtomUdQXOD6NcjlNlyBB7+rjjDr8lcTgyzObNVm1i/36btK9GDb8l8pHAshsXXpitXadVi+l01dc5n7174d13LR6wQgW/pXE4MsS2bTZy2L7dzEoXXOC3RD5TujQ0aGAK4vHHs7XrUBLlGgRZqohIuv4LEblXRP4UkaUi8qmIFBKRyiLyi4isEpExIlLAa1vQW1/t7a906pd3mjJypJWBvvtuvyVxODLEzp1mUdm4EaZMsZJdDnwruxFqotw8YDjwrvf+M2CliHRI7SARKQf0B2JUtS5WNvwa4CVgkKpWw+aaSCkOdCuwS1WrAoO8do6MkpxszunGjX2tAulwZJQ9e6BTJ3NMf/mlVTN3eHTo4EvZjVAUxHqgvqrGqGpDIBqbjrQd8HI6x+YDCnujjSLAVuAiYJy3/yPgcu99V28db39bERebmWG++w5WrnShrY4cxb590LmzRWWPG3cs/N/hkVJ2I5vzIUJREDVTZpIDUNVlmMJYm9ZBqvo3MBDYiCmGeMzxvVtVE71mm4GUwLVywCbv2ESvfakTzysivUVkgYgsiIuLC0H804zXX4dzzzX/g8ORAzh4EK64wuaSGjUKLrvMb4kiEJ/KboSiIFaIyFARaeUtb2PmpYLAkdQOEpGS2KigMnAuUBS4OEjTlCntgj3unjTdnaoO90YzMWXKlAlB/NOIZcvsB3THHTbFlsMR4Rw5Aj162IPxiBH23pEK7dvbrILZWHYjFAVxE7AauAe4F1jrbTsCtEnjuHbAOlWNU9UjwASgGVAiwMFdHtjivd8MVADw9hcHdmbgWhxvvmmT8PTu7bckDke6JCXZNNqTJllU9k03+S1RhNPBc/lmo5kpXQWhqgeAwcATwGPAG6q6X1WT05lZbiPQRESKeL6EtsAyYAaQYv/oCXzpvZ/krePtn66pTZjtOJmdOy166frrba5nhyOCSU6GXr1s6uWXX3bpOiHhQ9mNUEJVW2PO4/WYGaiCiPRU1VlpHaeqv4jIOGAhkAgswiKhvgY+E5FnvW0jvENGAB+LyGps5HBNZi7otOXdd+HAARfa6ohoDh2y2krDhsEHH8ATT8CAAX5LlUPwoeyGpPeQ7tVhuk5VV3jr1YFPvYgmX4mJidEFPqSfRxxHjsD559t8Dz/84Lc0YSUhwSqIfPON/T+KF7elRIng71PWixRxQV3ZTWKizfo2f/6x5fff7ecKphheesl9LxlizBi45hqYN++UsqpF5DdVjUmvXbojCCB/inIAUNWVIpI/05I5sp4vvrDaBLl0BpUjR2xUPXo0TJxoA6Vzz7XAjvh4W5KS0j7HicqkRAmoWNH0apUqx15Ll3Y3rMygatMWBCqDRYusVAbY3A0xMfC//1nyW6NGVrrbkUGyuexGKCOI97Fooo+9TdcD+VT15jDLli5uBOHRvLnVJ1i5EvLkjmnGVeGXXyzsccwYK7tw1lkW5XL99dCs2bEbuardiHbvPqYwUpbUtu3cCRs2wN9/H99vsWLHK4zzzz/2/rzzXHAYmP9g0yb47TdTBAsW2LJ7t+0vXBjq1z+mCBo1gqpVc81P039iYuxDnj0706fIyhFEX+BOLCtagFlYdrUjEpg/H+bOtezpXPAPXLnSRgqjR8OaNRaU1aWLVSzv2DH4DVrEcoiKFs14OegDB6zw7Zo1sHbtsdfly82MdfDgsbZ58piSSFEapUtDyZLHLyVKHHtfvHjO/UoOHrRoyjVrTl7WrbMpzgHy5bNaST16mCKIiYE6dWy7I0x06GCe/T17wj6tXrojCACvXlINbCSxwgtb9R03gsDunJMmmYkph87BuG2bjRJGjTJ9JwIXXWSXduWV/l1WcjJs3WoKI1B5pNwkd+wwO3tqiJiSOFFxpKwXLmwKsGDBY6+B74NtC3yfN68poJTlxPX0TGW7dgVXAGvW2Mgq8NZwxhk2igpcoqJsKVQoaz5vR4jMnAlt2lg9ki5dMnWKLBtBZDaKyZENbNlid9Z+/XKccti71/wJo0dbWHdSEkRHw8CB5oOLhIlh8uQxOcqVg5YtT96fYtratSv1Zffu49eXLTu2PXB0Es5rCLaoWnmLQM4+2278F110sjJwvpkIIrDsRiYVRKiEMhB8FehwYhQT4HsU02nP0KF2Z73rLr8lyRCzZlk5hT17zFH8wAPmV6hTx2/JMkagaat8+Ywfr2qmmkOHTFkcOpT6+2DbkpOPLUlJx6+nt6iaoz9FAZx/vvlfHDmAggXhxx+hVq2wd+WimHIqBw9aMHmXLvbvziEsXw6XXw7nnANffWX+9Zxqpz9VRI6ZjXLYANDhNw2z5/k8FAWxQERGcHwU02/hE8kREp98YqE9OSgx7t9/4ZJLIH9+cwCftlNIOhw5BBfFlBNRtaqtF1xgFR5zAPv3m1npn3/Mx+aUg8MR+aSrIFT1EPCatzgige+/hz/+sPKXOcBzmJRkEUnz51uVgMaN/ZbI4XCEQqrWXxHpKiJ3Bqz/IiJrvaV79ojnOAlVePRRC8i//nq/pQmJAQMs2XvQIPM/OByOnEFaI4gHOL5gXkGgETavwwfA2DDK5UiNCRMsbfWDD8y7GeEMHmyKoX//HOUucTgcpK0gCqjqpoD1n1R1B7BDRIqGWS5HMBIT4bHHLLztxhv9liZdJk2Ce+6Brl3hNWegdDhyHGkpiJKBK6raL2DVTTjgByNHWpzohAnZUur3VJg/3xLeGja0ZLgIF9fhcAQhrQj0X0Sk14kbRaQP8Gv4RHIE5eBBeOop8/BGuCF//XqLWCpbFiZPtkQyh8OR80hrBHEvMFFErsMm/QHLni4IRPYdKjcybJiV0Pzgg4iOXNq923IdDh2CGTNMSTgcjpxJqgpCVf8FmonIRUBKEYSvVXV6tkjmOEZCAjz3HLRrZ/XgI5TDh6243urVVq4+GyoBOByOMBJKHsR0wCkFP3ntNcuafv55vyVJFVW47TYbNXz8cY7J33M4HGlwmlbByUHExcGrr9qjeaNGfkuTKk8/bYrh//7PkuIcDkfOxymISOeFF6wu87PP+i1Jqnz4oSmIm2+2HD6Hw5E7cAoiktm0yeaZ7tkzYg36P/wAvXqZe+SddyLaf+5wODKIUxCRzNNPm3H/qaf8liQoS5ea5atmTRg3zqq0OhyO3INTEJHK8uUW0tq3r9VdijC2boVLL7Uch6+/tqk1HQ5H7sJNLR6pPP44FCkCjzzityQnsW8fdO5sczLPmhWR+svhcGQBYRtBiEgNEVkcsOwRkXtEJEpEfhaRP0RksoicGXDMwyKyWkRWiEjHcMkW8SxYYDab//0P/vMfv6U5iX79YNEimw67QQO/pXE4HOEibApCVVeoarSqRmMZ2PuBL4D3gIdUtZ63PgBARGpj1WPrAJ2At0Xk9Kzg88gjUKoU3Hef35KcxMiRFrX02GNmYnI4HLmX7PJBtAXWqOoGoAY2Kx3A98BV3vuuwGeqekhV1wGrgdNvapkZM2xCoEceibiJipcvhzvugFat4Mkn/ZbG4XCEm+xSENcAn3rvlwJdvPfdgQre+3JAYHnxzd624xCR3iKyQEQWxMXFhUlcn1CFhx+G8uXtThxBHDgAV18NhQu76qwOx+lC2BWEiBTAFELKBEO3AHeKyG/AGcDhlKZBDteTNqgOV9UYVY0pUyaXVR3/8kv45Rd7PC9UyCpffcwAAA+DSURBVG9pjuOee2yW048/hnInqW2Hw5EbyY4opouBhaq6DUBVlwMdAESkOpBiyd7MsdEEQHlgSzbIFxkkJVkacvXqcNNNfktzHJ99BsOHw4MPQqdOfkvjcDiyi+wwMV3LMfMSIvIf7zUP8BgwzNs1CbhGRAqKSGWgGqfTvBOjR8OyZVZSI1/kRB+vXg29e0OzZlZnyeFwnD6EVUGISBGgPTAhYPO1IrISWI6NED4AUNU/gc+BZcC3wJ2qmhRO+TKNKixZAsnJWXO+Q4fgiScsZvSqq9Jvn00cPGh+h3z54NNPXaa0w3G6EVYFoar7VbWUqsYHbHtDVat7y0OqqgH7nlPVKqpaQ1W/Cadsp8SwYRAdDbVrw/vv20QIp8Lw4bBhgxXmyxM5ye0DBli+w0cfuWQ4h+N0JHLuRjmFgwfNDFS3roX03HornH8+DBoEe/dm/Hx799r5WreG9u2zXNzMMn48vPUW3HuvTR/qcDhOP5yCyCjDh8OWLTB4MCxcCN9+C9WqWdbzeedZBNL27aGf7/XX4d9/bfQQIaVQ160zvdeoEbz4ot/SOBwOv5AAC0+OIyYmRhcsWJB9He7fb6OF2rVh+gmT7M2bZ3fTL7+0Gkq9eh1TGqmxY4edr00bmDgxvLKHyOHD0KIFrFxp5qXKlf2WyOFwZDUi8puqxqTXzo0gMsLQobBtm5XhPpEmTewm/+ef0K0bDBkCVarYLDp//RX8fC+9ZPNNR9BkQA8/DPPnw4gRTjk4HKc7TkGEyt69dkNv3x5atky9Xe3a5tVdvdqyoceMsW1XXGFJcCn8/beZqW64wfwZEcDkyTb99Z13RlQwlcPh8AmnIEJlyBCbHzrY6CEYFSvCG29YdNLjj8PMmTbKuOgimDoVnnnGkuNCPV+Y2bjRJq6rXx8GDvRbGofDEQk4H0Qo7Nlj9pYLL4QpUzJ3joQEc3C/9po5ucHqZg8enHVyZpIjRyyI6vffze9erZrfEjkcjnDifBBZyeDBsHPnqT3tn3GGle9euxbeew+6d7eRRQTw+OMwdy68+65TDg6H4xhuBJEe8fFQqZL5HSZNCm9fPvDtt3DxxRZ0NXy439I4HI7swI0gsorXX4fduyPGV5CV/P033Hgj1Ktn7hKHw+EIxCmItNi1y3wGV1xh3ttcRGIiXHedpXZ8/rklhTscDkcgkVM2NBJ57TVzUOfC0cMzz8CsWRaRW7Om39I4HI5IxI0gUmPHDjMvXX212WByEcOGWW7eTTfBf//rtzQOhyNScQoiNQYOhH37ctXky4cPw+23Q9++NvHPW2/5LZHD4YhknIIIxr//wptvwrXXWhZ0LmDbNmjbFt55Bx56yLKmixb1WyqHwxHJOB9EMF5+2cp6P/GE35JkCQsWmJ99xw6b+Oeaa/yWyOFw5ATcCOJEtm61sho33AA1avgtzSkzapSlcOTJA3PmOOXgcDhCxymIE3npJas9ESFZzpklMRHuv9/yHBo3tlFELovUdTgcYcaZmAL5+28L8enZE6pW9VuaTLNzp40Uvv/eKrMOGuTmk3Y4HBnHKYhAXnjBKqw+9pjfkmSaP/+Erl2tOuu778Jtt/ktkcPhyKk4BZFCyh31llty7Ew5EyeaSaloUasu3qyZ3xI5HI6cjPNBpPD88/b66KP+ypEJkpMt2fuKK6BWLfM3OOXgcDhOldN2BKEKIt7K+vU2x2afPmnPIR2BJCRYNvTEifb6zjtQqJDfUjkcjtzAaTmC+PNPaNoUfv3V2/Dss5A3r03InINYs8auY9Ikc0R/+KFTDg6HI+sIm4IQkRoisjhg2SMi94hItIjM87YtEJHGXnsRkTdFZLWI/C4iDcIl27Zt5nJo0gT63RhP/AcTrAZFuXLh6jLL+f57aNTIJqf77ju4556AEZHD4XBkAWFTEKq6QlWjVTUaaAjsB74AXgae9rY/4a0DXAxU85bewNBwyXbRRbB8Odx1FwwdfQY1k5fxWc2niPS5kxITbbTQpYvVUipXDubPh3bt/JbM4XDkRrLLxNQWWKOqGwAFzvS2Fwe8CZrpCoxUYx5QQkTOCZdAZ54Jb9y5kl+5kPJlj3Bt3xJ07AirV4erx8yzapXVT6pQwUJY58+HBx+En3+GKlX8ls7hcORWsktBXAN86r2/B3hFRDYBA/+/vbuPkao64zj+feqKxUJlKVhXIFBNaWKtC3RLEFuhxaKQBuhLCIZUVKIVCgVfkpKYGKj/1L7GktoK+AYxZUvVQhq0kFrbv1YFugKihcVAoNBlWwwWaWmVp3+cMzLM3tkdZmfuHZbfJ5nMmXvP3fvsmXvnmXvumXuBXMf/EOBA3jIH47QzmNmdsWtqS0dHR8+iWraMz/bdRctfLmL5cmhpgauvDvdKOHmyZ3+6p06cgDVrYMIEGDkyXFx27FhYvx4OHAiDrvr1yzZGEendqp4gzKwPMA1YFyfNA+5292HA3cBjuaoJi3fq9HH3Fe7e5O5NgwcPLj+wXbvClesWLuSChktZsCB0O82YEa7wfc018OKL5f/5crjD1q0wfz40NIRRSYcOhd/vHTgQksO0aVB33o49E5E0pXEEMQXY5u7t8fUc4NlYXgeMjeWDwLC85YZyuvup8pYtC78ou+++DyZdfjmsXQsvvBD6+ydNCj88a2/v4u9UwNtvh3szjB4NTU3wxBOhK+mll2D37tC91FC1zjYRkWRpJIibOd29BOFDf0IsfwnYE8sbgFviaKZxwDF3P1yViHbsCDdiXrQIBg3qNPvGG2HnznDFjebmcEvORx8NP0irlFOnwhHK7Nnhw3/hwnBk8Mgj4YKyq1eH7iWNTBKRrFS1s8LMLga+DHwrb/IdwMNmVgf8hzBiCWAjMBVoI4x4uq1qgXV0QGMj3HNP0Sp9+8KDD4YP8HnzwijYJ58M1/JrbCxtNe7hwnn794ff4u3ff7rc2hrKAwbAHXfA3LkwalQl/jkRkcowr/WxnV1oamryLVu2lLfwGT+l7r7qmjVw772hO2jxYli6NPRQtbefmQAKE8G77575t/r1g+HDw8ViZ84Ml8fo27e8f0FEpBxmttXdm7qtd94miDIcPRrOB6xcGYbJnjzZebRTfT2MGBGSwPDhncv19eo2EpFslZogNB7mLAwcCCtWwK23wqpV4fRFYSLo3z/rKEVEKkMJogzjx+tqqSLS+52XF+sTEZHuKUGIiEgiJQgREUmkBCEiIomUIEREJJEShIiIJFKCEBGRREoQIiKS6Jy+1IaZdQD7y1x8EPCPCoZTabUeH9R+jIqvZxRfz9RyfMPdvdsb6pzTCaInzGxLKdciyUqtxwe1H6Pi6xnF1zO1Hl8p1MUkIiKJlCBERCTR+ZwgVmQdQDdqPT6o/RgVX88ovp6p9fi6dd6egxARka6dz0cQIiLSBSUIERFJ1OsThJndZGZ/NbM2M1uSMP8iM2uO8182sxEpxjbMzP5oZm+Y2etmtiihzkQzO2ZmrfHxQFrxxfXvM7Mdcd2d7u9qwc9i+203szEpxvapvHZpNbN3zGxxQZ3U28/MHjezI2a2M2/aQDPbbGZ74nN9kWXnxDp7zGxOivH90MzejO/hc2Y2oMiyXW4PVYxvqZn9Le99nFpk2S739yrG15wX2z4zay2ybNXbr6Lcvdc+gAuAvcAVQB/gNeCqgjrzgV/G8iygOcX4GoAxsdwf2J0Q30Tgdxm24T5gUBfzpwLPAwaMA17O8L3+O+EHQJm2H3A9MAbYmTftB8CSWF4CPJSw3EDgrfhcH8v1KcU3GaiL5YeS4itle6hifEuB+0rYBrrc36sVX8H8HwMPZNV+lXz09iOIsUCbu7/l7v8F1gLTC+pMB56K5d8Ak8zM0gjO3Q+7+7ZY/hfwBjAkjXVX0HRgtQctwAAza8ggjknAXncv95f1FePufwaOFkzO386eAmYkLHojsNndj7r728Bm4KY04nP3Te7+XnzZAgyt9HpLVaT9SlHK/t5jXcUXPztmAr+q9Hqz0NsTxBDgQN7rg3T+AP6gTtxBjgEfSyW6PLFrazTwcsLsa83sNTN73sw+nWpg4MAmM9tqZncmzC+ljdMwi+I7ZZbtl/Nxdz8M4YsBcGlCnVppy9sJR4VJutseqmlB7AJ7vEgXXS203xeAdnffU2R+lu131np7gkg6Eigc11tKnaoys37AM8Bid3+nYPY2QrdJI7Ac+G2asQHXufsYYArwbTO7vmB+LbRfH2AasC5hdtbtdzZqoS3vB94Dni5SpbvtoVp+AVwJjAIOE7pxCmXefsDNdH30kFX7laW3J4iDwLC810OBQ8XqmFkdcAnlHd6WxcwuJCSHp9392cL57v6Oux+P5Y3AhWY2KK343P1QfD4CPEc4jM9XShtX2xRgm7u3F87Iuv3ytOe63uLzkYQ6mbZlPCn+FWC2xw7zQiVsD1Xh7u3u/r67nwJWFllv1u1XB3wNaC5WJ6v2K1dvTxCvAp80s0/Eb5mzgA0FdTYAudEi3wBeLLZzVFrsr3wMeMPdf1KkzmW5cyJmNpbwnv0zpfg+Ymb9c2XCicydBdU2ALfE0UzjgGO5rpQUFf3WlmX7FcjfzuYA6xPq/B6YbGb1sQtlcpxWdWZ2E/BdYJq7nyhSp5TtoVrx5Z/X+mqR9Zayv1fTDcCb7n4waWaW7Ve2rM+SV/tBGGWzmzC64f447XuEHQHgw4SuiTbgFeCKFGP7POEQeDvQGh9TgbuAu2KdBcDrhBEZLcD4FOO7Iq73tRhDrv3y4zPg57F9dwBNKb+/FxM+8C/Jm5Zp+xGS1WHgf4RvtXMJ57X+AOyJzwNj3SZgVd6yt8dtsQ24LcX42gj997ntMDey73JgY1fbQ0rxrYnb13bCh35DYXzxdaf9PY344vQnc9tdXt3U26+SD11qQ0REEvX2LiYRESmTEoSIiCRSghARkURKECIikkgJQkREEtVlHYDIucDMcsNUAS4D3gc64usT7j4+k8BEqkjDXEXOkpktBY67+4+yjkWkmtTFJNJDZnY8Pk80sz+Z2a/NbLeZfd/MZpvZK/EeAFfGeoPN7BkzezU+rsv2PxBJpgQhUlmNwCLgM8A3gZHuPhZYBSyMdR4GfurunwO+HueJ1BydgxCprFc9XovKzPYCm+L0HcAXY/kG4Kq824581Mz6e7gniEjNUIIQqayTeeVTea9PcXp/+xBwrbv/O83ARM6WuphE0reJcBFBAMxsVIaxiBSlBCGSvu8ATfHuaLsIV58VqTka5ioiIol0BCEiIomUIEREJJEShIiIJFKCEBGRREoQIiKSSAlCREQSKUGIiEii/wNyAm975Z5fygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_test = pd.read_csv(r'G:\\dAtAsS\\Google_Stock_Price_Test.txt')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 80):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_stock_price=dataset_test.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_total=pd.concat((dataset_train['Open'], dataset_test['Open']), axis=0)\n",
    "inputs=dataset_total[len(dataset_total)-len(dataset_test)-60:].values\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=inputs.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=min_max.fit_transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "# Getting the predicted stock price of 2017\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "x_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[]\n",
    "\n",
    "for i in range(60,80):\n",
    "    x_test.append(inputs[i-60:i,0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-6e756bb6a89f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "x_test=np.array(x_test)\n",
    "x_test=np.reshape(x_test,(x_test.shape[0], x_test.shape[1], 1))\n",
    "predict=seq.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60, 80):\n",
    "    x_test.append(inputs[i-60:i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
